{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import doubleml as dml\n",
    "import patsy\n",
    "\n",
    "# Define random state\n",
    "np.random.seed(123)\n",
    "rs = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fullly preprocessed dataset\n",
    "filepath = \"../data_processing/processed_merged_data/full_dataset.csv\"\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform GVA_Real_Density and Tax_D_Real\n",
    "df['GVA_Real_Density'] = np.log(df['GVA_Real_Density'])\n",
    "df['Tax_D_Real'] = np.log(df['Tax_D_Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutoff values based on the propensity score analysis\n",
    "tax_cutoff = 7.2 # Justify with generalised propensity score\n",
    "gva_cutoff = 11 # Justify with scatter plot\n",
    "\n",
    "# Find LANMs that are outside of range consistently\n",
    "outliers = df.groupby('LANM').filter(\n",
    "    lambda x: x['Tax_D_Real'].mean() < tax_cutoff and \n",
    "    x['GVA_Real_Density'].mean() > gva_cutoff\n",
    ")\n",
    "\n",
    "outliers = outliers['LANM'].unique()\n",
    "print(f\"List of Outlier LAs: {outliers}\")\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "df = df[~df['LANM'].isin(outliers)]\n",
    "\n",
    "# Calculate total missing rows\n",
    "num_years = df['Year'].nunique()\n",
    "dropped_rows = len(outliers) * num_years\n",
    "print(f\"Number of rows dropped: {dropped_rows}\")\n",
    "print(f\"Rows of data remaining: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove alternate outcome \"GVA_Real\"\n",
    "ml_df = df.drop(columns=['GVA_Real'])\n",
    "\n",
    "# Remove all cols with GDHI in the name (mediators)\n",
    "ml_df = ml_df.loc[:, ~ml_df.columns.str.contains('GDHI')]\n",
    "\n",
    "# Remove non time-varying variables\n",
    "ml_df = ml_df.drop(columns=['Area', 'Region', 'Authority_Type'])\n",
    "\n",
    "# Remove id name columns\n",
    "ml_df = ml_df.drop(columns=['LANM'])\n",
    "\n",
    "# Duplicate year column\n",
    "ml_df['Year_Group'] = ml_df['Year'].astype('str')\n",
    "\n",
    "# Duplicate LACD column\n",
    "ml_df['LACD_Group'] = ml_df['LACD'].astype('str')\n",
    "\n",
    "# Create one hot encoding for fixed effects\n",
    "ml_df = pd.get_dummies(ml_df, columns=['LACD'])\n",
    "\n",
    "# Show columns and number of columns\n",
    "print(ml_df.columns)\n",
    "print(len(ml_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Nuisance Parameter Learners\n",
    "ml_l =  RandomForestRegressor(random_state=rs)\n",
    "ml_m = RandomForestRegressor(random_state=rs)\n",
    "\n",
    "# Define two-dimensional clustering\n",
    "clusters = ['LACD_Group', 'Year_Group']\n",
    "\n",
    "# Create DoubleML cluster data object\n",
    "obj_dml_data = dml.DoubleMLClusterData(ml_df,\n",
    "                                       'GVA_Real_Density',\n",
    "                                       'Tax_D_Real',\n",
    "                                       clusters)\n",
    "\n",
    "# Create DoubleML Partially Linear Regression object\n",
    "dml_plr_obj = dml.DoubleMLPLR(obj_dml_data, ml_l, ml_m)\n",
    "\n",
    "# Define parameter grids for tuning\n",
    "par_grids = {'ml_l': {'n_estimators': [300, 400, 600, 800],\n",
    "                     'max_features': [0.2, 0.5, 0.8],\n",
    "                     'max_depth': [ None, 30, 40, 50],\n",
    "                     'min_samples_split': [2, 4, 8],\n",
    "                     'min_samples_leaf': [1, 2, 5]},\n",
    "            'ml_m': {'n_estimators': [400, 600, 800, 1000],\n",
    "                     'max_features': [0.2, 0.5, 0.8],\n",
    "                     'max_depth': [ None, 30, 40, 50],\n",
    "                     'min_samples_split': [2, 4, 8],\n",
    "                     'min_samples_leaf': [1, 2, 5]}}\n",
    "\n",
    "# Tune hyperparameters\n",
    "dml_plr_obj.tune(par_grids, search_mode='randomized_search', \n",
    "                 n_iter_randomized_search=50)\n",
    "\n",
    "# Print optimal hyperparameters\n",
    "print(dml_plr_obj.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit DML model\n",
    "print(dml_plr_obj.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spline basis functions from df\n",
    "spline_basis = patsy.dmatrix(\n",
    "    \"bs(GDHI_Total_Real_Density, df=5, degree=3)\", df)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "spline_basis_df = pd.DataFrame(spline_basis, \n",
    "                               columns=spline_basis.design_info.column_names)\n",
    "\n",
    "# Estimate CATE using previously trained DML model\n",
    "cate = dml_plr_obj.cate(spline_basis_df)\n",
    "print(cate)\n",
    "\n",
    "# Create a new grid for GDHI_Total_Real_Density for evaluation\n",
    "new_data = {\"GDHI_Total_Real_Density\": np.linspace(\n",
    "    df['GDHI_Total_Real_Density'].min(),\n",
    "    df['GDHI_Total_Real_Density'].max(), 100)}\n",
    "\n",
    "# Use the same design to create basis functions for the new grid\n",
    "spline_grid = pd.DataFrame(patsy.build_design_matrices(\n",
    "    [spline_basis.design_info], new_data)[0])\n",
    "\n",
    "# Ensure columns in the new grid match the original basis\n",
    "spline_grid.columns = spline_basis_df.columns\n",
    "\n",
    "# Calculate confidence intervals via bootstrapping\n",
    "df_cate = cate.confint(spline_grid, level=0.95, joint=True, n_rep_boot=2000)\n",
    "print(df_cate)\n",
    "\n",
    "# Visualise results\n",
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "df_cate['GDHI_Total_Real_Density'] = new_data['GDHI_Total_Real_Density']\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(True, axis='y', linestyle='-', linewidth=0.5, color='lightgray')\n",
    "\n",
    "# Plot estimated effect with higher zorder\n",
    "ax.plot(df_cate['GDHI_Total_Real_Density'], \n",
    "        df_cate['effect'], \n",
    "        label='Estimated Elasticity', \n",
    "        color='black', \n",
    "        linewidth=2, \n",
    "        zorder=3)\n",
    "\n",
    "ax.fill_between(df_cate['GDHI_Total_Real_Density'], \n",
    "                df_cate['2.5 %'], \n",
    "                df_cate['97.5 %'], \n",
    "                color='cornflowerblue', \n",
    "                alpha=.3, \n",
    "                label='Confidence Interval (95%)', \n",
    "                zorder=2)\n",
    "\n",
    "# Remove borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Gross Domestic Household Income Per Capita (Â£, Real)', fontsize=18)\n",
    "plt.ylabel('Elasticity', fontsize=18)\n",
    "\n",
    "# Define legend parameters\n",
    "plt.legend(frameon=False, loc='upper left')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('./figures/elasticity_plot.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
